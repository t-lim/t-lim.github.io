{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674bafc9",
   "metadata": {},
   "source": [
    "# Appendix: Introduction to using HF transformers\n",
    "\n",
    "This appendix introduces the basics of using the Hugging Face transformers package, for the example task of fine-tuning an encoder-only transformer model, Electra (released by Google in 2020) to perform medical natural language inference.\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "https://huggingface.co/docs/transformers/en/training\n",
    "\n",
    "https://github.com/gregdurrett/fp-dataset-artifacts\n",
    "\n",
    "- many portions of the code below were adapted from Greg Durrett's NLP course package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ceb2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, EvalPrediction, TrainingArguments\n",
    "import datasets\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb2519",
   "metadata": {},
   "source": [
    "\n",
    "## Set paramaters\n",
    "\n",
    "TrainingArguments\n",
    "- num_train_epochs — Total number of training epochs to perform\n",
    "- per_device_train_batch — try to make this as large as you can without getting CUDA out-of-memory errors\n",
    "- eval_steps — Interval between two evaluations. Should be an integer as number of update steps, or a float in range [0,1) as ratio of total training steps.\n",
    "- logging_steps — Number of update steps between two logs\n",
    "- save_steps — Number of updates steps before two checkpoint saves.\n",
    "- report_to — Platforms to report the results and logs to, such as \"azure_ml\", \"clearml\", \"codecarbon\", \"comet_ml\", \"dagshub\", \"dvclive\", \"flyte\", \"mlflow\", \"neptune\", \"tensorboard\", and \"wandb\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e997a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained transformer model to use\n",
    "model_id = 'google/electra-base-discriminator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407afebb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Args:\n",
    "    model_id : str = model_id\n",
    "    output_dir : str = os.path.join('models', model_id)\n",
    "    eval_dir : str = os.path.join(output_dir,\n",
    "                                  'logs',\n",
    "                                  datetime.now().strftime(\"%Y%m%d-%H%M\"))\n",
    "    dataset : str = 'snli'\n",
    "    max_length : int = 128 \n",
    "    max_train_samples: int = -1  # limit number of examples to train on\n",
    "    max_dev_samples: int = -1    # limit number of examples to validate with\n",
    "    max_test_samples: int = -1   # limit number of examples to test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95f57df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for this run\n",
    "args = Args(dataset = dict(train='mednli/mli_train_v1.jsonl',\n",
    "                           dev='mednli/mli_dev_v1.jsonl',\n",
    "                           test='mednli/mli_test_v1.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2812139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=args.output_dir,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=8.0,\n",
    "    per_device_train_batch_size=32,\n",
    "    evaluation_strategy='steps',\n",
    "    save_steps= 0.2,          # checkpoint interval\n",
    "    logging_steps = 0.1,      # logging interval\n",
    "    eval_steps = 0.1,         # evaluation interval\n",
    "    report_to=\"tensorboard\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4bb229",
   "metadata": {},
   "source": [
    "## Load the model and tokenizer\n",
    "\n",
    "Select to load model from HF hub, or previously checkpoint-saved folder\n",
    "This should either be a HuggingFace model ID (see https://huggingface.co/models)\n",
    "or a path to a saved model checkpoint (a folder containing\n",
    "config.json and model.save_tensors)\n",
    "\n",
    "Auto Classes automatically retrieve the relevant model architecture with the right model fine-tuning head.\n",
    "\n",
    "The AutoTokenizer.from_pretrained() class method will be instantiated with one of the tokenizer classes for preparing inputs for a model. The library contains tokenizers for all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6017e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model architecture\n",
    "model_class = AutoModelForSequenceClassification\n",
    "\n",
    "# Where to load model from\n",
    "from_checkpoint = args.model_id     # load pre-trained from HF hub\n",
    "#from_checkpoint = args.output_dir   # load from local folder\n",
    "#from_checkpoint = os.path.join(args.output_dir, \"checkpoint-6740\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "154c8961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = model_class.from_pretrained(from_checkpoint, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "069ec0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model_id, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab3f5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26140c85",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "NLI models need to have the output label count specified\n",
    "(label 0 is \"entailed\", 1 is \"neutral\", and 2 is \"contradiction\")\n",
    "\n",
    "If not default SNLI, need to format the json dataset appropriately,\n",
    "with each line containing one example as follows:\n",
    "{\"premise\": \"Two women are embracing.\", \n",
    " \"hypothesis\": \"The sisters are hugging.\",\n",
    " \"label\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4fa0cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train : mednli/mli_train_v1.jsonl ...\n",
      "Loading dev : mednli/mli_dev_v1.jsonl ...\n",
      "Loading test : mednli/mli_test_v1.jsonl ...\n"
     ]
    }
   ],
   "source": [
    "nli_labels = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n",
    "if args.dataset == 'snli':\n",
    "    dataset = datasets.load_dataset('snli')\n",
    "else:\n",
    "    dataset = datasets.DatasetDict()\n",
    "    def prepare_label(ex):\n",
    "        \"\"\"To pre-process mednli dataset examples\"\"\"\n",
    "        lab = ex['label']\n",
    "        ex['label'] = nli_labels[lab] if lab in nli_labels else -1\n",
    "        return ex\n",
    "    \n",
    "    for split in args.dataset.keys():\n",
    "        print('Loading', split, ':', args.dataset[split], '...')\n",
    "        \n",
    "        # By default, \"json\" loader places all examples in the \"train\" split\n",
    "        dataset[split] = datasets\\\n",
    "            .load_dataset('json', data_files=args.dataset[split])['train']\\\n",
    "            .rename_columns({'gold_label': 'label',\n",
    "                             'sentence1': 'premise',\n",
    "                             'sentence2': 'hypothesis'})\\\n",
    "            .select_columns(['label', 'premise', 'hypothesis'])\\\n",
    "            .map(prepare_label)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682f0ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'premise', 'hypothesis'],\n",
       "        num_rows: 11232\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['label', 'premise', 'hypothesis'],\n",
       "        num_rows: 1395\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'premise', 'hypothesis'],\n",
       "        num_rows: 1422\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove NLI examples with no label\n",
    "dataset = dataset.filter(lambda ex: int(ex['label']) in nli_labels.values())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91509cee",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25d5b44d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(examples, tokenizer=tokenizer, max_length=args.max_length):\n",
    "    \"\"\"Preprocess an NLI dataset, tokenizing premises and hypotheses\"\"\"\n",
    "    max_length = max_length if max_length else tokenizer.model_max_length\n",
    "    tokenized_examples = tokenizer(examples['premise'],\n",
    "                                   examples['hypothesis'],\n",
    "                                   truncation=True,\n",
    "                                   max_length=max_length,\n",
    "                                   padding='max_length')\n",
    "    tokenized_examples['label'] = examples['label']\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8509e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train and dev set splits\n",
    "if training_args.do_train:\n",
    "    train_dataset = dataset['train']\n",
    "    if args.max_train_samples > 0:\n",
    "        train_dataset = train_dataset.select(range(args.max_train_samples))\n",
    "    train_dataset_tokenized = \\\n",
    "        train_dataset.map(prepare_dataset,\n",
    "                          batched=True,\n",
    "                          remove_columns=train_dataset.column_names)\n",
    "    dev_dataset = dataset['dev']\n",
    "    if args.max_dev_samples > 0:\n",
    "        dev_dataset = dev_dataset.select(range(args.max_dev_samples))\n",
    "    dev_dataset_tokenized = \\\n",
    "        dev_dataset.map(prepare_dataset,\n",
    "                        batched=True,\n",
    "                        remove_columns=dev_dataset.column_names)\n",
    "else:\n",
    "    train_dataset = None\n",
    "    train_dataset_tokenized = None\n",
    "    dev_dataset = None\n",
    "    dev_dataset_tokenized = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7ffd888",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1422/1422 [00:00<00:00, 14380.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare test set\n",
    "if training_args.do_eval:\n",
    "    test_dataset = dataset['test']\n",
    "    if args.max_test_samples > 0:\n",
    "        test_dataset = test_dataset.select(range(args.max_test_samples))\n",
    "    test_dataset_tokenized = \\\n",
    "        test_dataset.map(prepare_dataset,\n",
    "                         batched=True,\n",
    "                         remove_columns=test_dataset.column_names)\n",
    "else:\n",
    "    test_dataset = None\n",
    "    test_dataset_tokenized = None    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364aeac6",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Trainer is a complete training and evaluation loop implemented in the Transformers library. You only need to pass it the necessary pieces for training: model, tokenizer, dataset, evaluation function, and hyperparameters.\n",
    "\n",
    "If you want to use custom evaluation metrics, provide your own compute_metrics() function\n",
    "\n",
    "If you want to customize the way the loss is computed, you should subclass Trainer and override the \"compute_loss\" method (see https://huggingface.co/transformers/_modules/transformers/trainer.html#Trainer.compute_loss).\n",
    "\n",
    "You can also add training hooks using Trainer.add_callback: See https://huggingface.co/transformers/main_classes/trainer.html#transformers.Trainer.add_callback and https://huggingface.co/transformers/main_classes/callback.html#transformers.TrainerCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc7307fb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# If you want to use custom metrics, define your own \"compute_metrics\" function.\n",
    "def compute_metrics(eval_prediction: EvalPrediction):\n",
    "    \"\"\"computes sentence-classification accuracy\"\"\"\n",
    "    return {'accuracy': (np.argmax(eval_prediction.predictions, axis=1) ==\n",
    "                         eval_prediction.label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5aa20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to change how predictions are computed, you should\n",
    "# subclass Trainer and override the \"prediction_step\" method\n",
    "# (see https://huggingface.co/transformers/_modules/transformers/trainer.html#Trainer.prediction_step).\n",
    "# If you do this your custom prediction_step should probably start by\n",
    "# calling super().prediction_step and modifying the values that it returns\n",
    "trainer = Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=train_dataset_tokenized,\n",
    "                  eval_dataset=dev_dataset_tokenized,\n",
    "                  tokenizer=tokenizer,\n",
    "                  compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52403176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 281/2808 [02:47<25:40,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7606, 'grad_norm': 5.441277027130127, 'learning_rate': 4.4996438746438744e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 10%|█         | 281/2808 [02:57<25:40,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5451989769935608, 'eval_accuracy': 0.7820788621902466, 'eval_runtime': 10.0562, 'eval_samples_per_second': 138.72, 'eval_steps_per_second': 17.402, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 562/2808 [05:43<22:38,  1.65it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5005, 'grad_norm': 5.723459720611572, 'learning_rate': 3.999287749287749e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 562/2808 [05:52<22:38,  1.65it/s]Checkpoint destination directory models/google/electra-base-discriminator/checkpoint-562 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5031224489212036, 'eval_accuracy': 0.8057347536087036, 'eval_runtime': 9.6876, 'eval_samples_per_second': 143.998, 'eval_steps_per_second': 18.064, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 843/2808 [08:40<19:45,  1.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3853, 'grad_norm': 4.627773284912109, 'learning_rate': 3.498931623931624e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 30%|███       | 843/2808 [08:50<19:45,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5096697807312012, 'eval_accuracy': 0.8179211616516113, 'eval_runtime': 10.0252, 'eval_samples_per_second': 139.15, 'eval_steps_per_second': 17.456, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1124/2808 [11:36<16:45,  1.68it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3047, 'grad_norm': 7.183603286743164, 'learning_rate': 2.9985754985754986e-05, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 40%|████      | 1124/2808 [11:46<16:45,  1.68it/s]Checkpoint destination directory models/google/electra-base-discriminator/checkpoint-1124 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5592992305755615, 'eval_accuracy': 0.8272401690483093, 'eval_runtime': 10.0634, 'eval_samples_per_second': 138.622, 'eval_steps_per_second': 17.39, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1405/2808 [14:35<14:01,  1.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2257, 'grad_norm': 7.553471088409424, 'learning_rate': 2.4982193732193735e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 50%|█████     | 1405/2808 [14:45<14:01,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5295200943946838, 'eval_accuracy': 0.8250896334648132, 'eval_runtime': 10.0387, 'eval_samples_per_second': 138.962, 'eval_steps_per_second': 17.432, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1686/2808 [17:32<11:12,  1.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1495, 'grad_norm': 1.6455395221710205, 'learning_rate': 1.997863247863248e-05, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 60%|██████    | 1686/2808 [17:42<11:12,  1.67it/s]Checkpoint destination directory models/google/electra-base-discriminator/checkpoint-1686 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6505078673362732, 'eval_accuracy': 0.832974910736084, 'eval_runtime': 10.056, 'eval_samples_per_second': 138.723, 'eval_steps_per_second': 17.403, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1967/2808 [20:31<08:28,  1.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.114, 'grad_norm': 7.634776592254639, 'learning_rate': 1.4975071225071227e-05, 'epoch': 5.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 70%|███████   | 1967/2808 [20:41<08:28,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7827601432800293, 'eval_accuracy': 0.832974910736084, 'eval_runtime': 10.0688, 'eval_samples_per_second': 138.546, 'eval_steps_per_second': 17.38, 'epoch': 5.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2248/2808 [23:25<05:31,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0954, 'grad_norm': 1.790868878364563, 'learning_rate': 9.971509971509972e-06, 'epoch': 6.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 80%|████████  | 2248/2808 [23:35<05:31,  1.69it/s]Checkpoint destination directory models/google/electra-base-discriminator/checkpoint-2248 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8643640279769897, 'eval_accuracy': 0.832974910736084, 'eval_runtime': 9.8849, 'eval_samples_per_second': 141.125, 'eval_steps_per_second': 17.704, 'epoch': 6.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 2529/2808 [26:21<02:45,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0653, 'grad_norm': 0.3601096272468567, 'learning_rate': 4.9679487179487175e-06, 'epoch': 7.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 90%|█████████ | 2529/2808 [26:31<02:45,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8337998390197754, 'eval_accuracy': 0.8365591168403625, 'eval_runtime': 9.8705, 'eval_samples_per_second': 141.331, 'eval_steps_per_second': 17.73, 'epoch': 7.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2808/2808 [29:13<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1753.89, 'train_samples_per_second': 51.232, 'train_steps_per_second': 1.601, 'train_loss': 0.26511958046176837, 'epoch': 8.0}\n"
     ]
    }
   ],
   "source": [
    "if training_args.do_train:    \n",
    "    print('Training the model...')\n",
    "    trainer.train()\n",
    "    trainer.save_model(args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d3227",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "\n",
    "accuracy_score()\n",
    "- Accuracy: fraction of correct predictions\n",
    "\n",
    "classification_report()\n",
    "- Precision: number of true positives divided by the number of true positives plus the number of false positives\n",
    "- Recall: number of true positives divided by the number of true positives plus the number of false negatives \n",
    "- F1-score: harmonic mean of precision and recall\n",
    "- Macro average: averages the unweighted mean per label\n",
    "- Weighted average: averages the support-weighted mean per label\n",
    "\n",
    "confusion matrix()\n",
    "- $C_{ij}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de7d0f46",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [00:10<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.982203483581543, 'test_accuracy': 0.8087201118469238, 'test_runtime': 10.4103, 'test_samples_per_second': 136.596, 'test_steps_per_second': 17.098}\n",
      "Accuracy: 0.809\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.87      0.89      0.88       462\n",
      "     entailed       0.78      0.77      0.78       481\n",
      "      neutral       0.77      0.76      0.77       479\n",
      "\n",
      "     accuracy                           0.81      1422\n",
      "    macro avg       0.81      0.81      0.81      1422\n",
      " weighted avg       0.81      0.81      0.81      1422\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[412  23  27]\n",
      " [ 28 372  81]\n",
      " [ 34  79 366]]\n"
     ]
    }
   ],
   "source": [
    "if training_args.do_eval:\n",
    "    print('Evaluating results:')\n",
    "    predictions, _, results = trainer.predict(test_dataset=test_dataset_tokenized)\n",
    "    print(results)\n",
    "\n",
    "    os.makedirs(args.eval_dir, exist_ok=True)\n",
    "    with open(os.path.join(args.eval_dir, 'metrics.json'),\n",
    "              encoding='utf-8', mode='w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    labels= {0: \"entailed\", 1: \"neutral\", 2: \"contradiction\"}\n",
    "    with open(os.path.join(args.eval_dir, 'predictions.jsonl'),\n",
    "              encoding='utf-8', mode='w') as f:\n",
    "        y_true = list()\n",
    "        for i, example in enumerate(test_dataset):\n",
    "            ex = dict(example)\n",
    "            ex['predicted_scores'] = predictions[i].tolist()\n",
    "            ex['predicted_label'] = int(predictions[i].argmax())\n",
    "            y_true.append(labels[ex['predicted_label']])\n",
    "            f.write(json.dumps(ex))\n",
    "            f.write('\\n')\n",
    "\n",
    "    y_pred = [labels[label] for label in test_dataset['label']]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "                \n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)                \n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "\n",
    "    # Generate confusion matrix                                                       \n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
